#!/usr/bin/env python3
"""
STEP NEXT-10B-2G â€” Step7 Amount ì „ìˆ˜ ì¡°ì‚¬ (Ground Truth Audit)

ê°€ì…ì„¤ê³„ì„œ(Proposal)ì—ì„œ ì§ì ‘ ì¶”ì¶œí•œ (coverage_name_raw, amount_raw)ë¥¼
ground-truthë¡œ í•˜ì—¬ Step7 amount ê²°ê³¼ì™€ ë¹„êµ ì¡°ì‚¬.

ê¸ˆì§€:
- Type Cì—ì„œ "ë³´í—˜ê°€ì…ê¸ˆì•¡"ì„ ë‹´ë³´ë³„ amountë¡œ ì±„ìš°ê¸°
- ì•½ê´€/ìƒí’ˆìš”ì•½ì„œ textë¥¼ heuristicsë¡œ ê¸ì–´ì„œ ë‹´ë³´ë³„ ê¸ˆì•¡ ìƒì„±
- UNCONFIRMED ë¹„ìœ¨ì„ KPIë¡œ ì‚¼ì•„ ì–µì§€ë¡œ ë‚®ì¶”ê¸°
"""
import json
import re
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import defaultdict
from dataclasses import dataclass, asdict
import csv


@dataclass
class GTAmountPair:
    """Ground Truth: ê°€ì…ì„¤ê³„ì„œì—ì„œ ì¶”ì¶œí•œ ì›ë³¸ í˜ì–´"""
    coverage_name_raw: str
    amount_raw: str
    page_num: int
    line_text: str  # ì¶”ì¶œ ì›ë¬¸ (ì¦ê±°)


@dataclass
class MappingResult:
    """GT ë‹´ë³´ëª… â†’ coverage_code ë§¤í•‘ ê²°ê³¼"""
    gt_pair: GTAmountPair
    coverage_code: Optional[str]
    mapping_status: str  # matched / unmatched
    normalized_name: str  # ì •ê·œí™”ëœ ë‹´ë³´ëª…


@dataclass
class ComparisonResult:
    """Step7 ê²°ê³¼ì™€ GT ë¹„êµ"""
    coverage_code: str
    gt_amount_raw: str
    step7_value_text: Optional[str]
    step7_status: Optional[str]
    step7_source_priority: Optional[str]
    step7_source_doc_type: Optional[str]
    step7_source_page: Optional[int]
    step7_evidence_snippet: Optional[str]
    verdict: str  # OK_MATCH / MISS_PATTERN / MISMATCH_VALUE / TYPE_C_EXPECTED_UNCONFIRMED / GT_AMBIGUOUS
    gt_page: int
    gt_line: str
    proposal_file: str  # ì–´ëŠ ê°€ì…ì„¤ê³„ì„œ íŒŒì¼ì—ì„œ ì™”ëŠ”ì§€
    risk_signals: List[str]  # ë¦¬ìŠ¤í¬ ì‹œê·¸ë„ ëª©ë¡


def normalize_coverage_name(raw_name: str) -> str:
    """ë‹´ë³´ëª… ì •ê·œí™”: ê³µë°±/ê´„í˜¸/ì ‘ë‘ì–´/ë²ˆí˜¸ ì œê±°"""
    # Remove leading numbers like "1. ", "3. ", etc.
    name = re.sub(r'^\d+\.\s*', '', raw_name)
    # Remove leading tags like [ê¸°ë³¸ê³„ì•½], [ê°±ì‹ í˜•], etc.
    name = re.sub(r'^\[.*?\]\s*', '', name)
    # Remove all whitespace
    name = re.sub(r'\s+', '', name)
    # Remove parentheses content
    name = re.sub(r'\([^)]*\)', '', name)
    # Remove special chars (including special dash variants)
    name = re.sub(r'[Â·\-_\u2022\u2023\u25E6\u2043\u2219]', '', name)
    return name.strip()


def extract_amount_from_text(text: str) -> Optional[str]:
    """
    ê¸ˆì•¡ íŒ¨í„´ ì¶”ì¶œ (KB ì‚¬ê±´ ì¬ë°œ ë°©ì§€ - ì²œë§Œì›/ë°±ë§Œì› íŒ¨í„´ ì§€ì›)

    ì§€ì› íŒ¨í„´:
    - 1,000ë§Œì›, 3000ë§Œì›
    - 1ì²œë§Œì›, 5ë°±ë§Œì›, 2ì‹­ë§Œì›
    - 100,000ì›, 10ë§Œì›
    """
    # íŒ¨í„´ 1: N,NNNë§Œì›, NNNNë§Œì›
    pattern1 = re.search(r'(\d{1,3}(?:,\d{3})*ë§Œ?ì›)', text)
    if pattern1:
        return pattern1.group(1)

    # íŒ¨í„´ 2: Nì²œë§Œì›, Në°±ë§Œì›, Nì‹­ë§Œì›
    pattern2 = re.search(r'(\d+[ì²œë°±ì‹­]ë§Œ?ì›)', text)
    if pattern2:
        return pattern2.group(1)

    # íŒ¨í„´ 3: NNN,NNNì›, NNNNNNì›
    pattern3 = re.search(r'(\d{1,3}(?:,\d{3})+ì›)', text)
    if pattern3:
        return pattern3.group(1)

    # íŒ¨í„´ 4: Në§Œì›
    pattern4 = re.search(r'(\d+ë§Œ?ì›)', text)
    if pattern4:
        return pattern4.group(1)

    return None


def detect_risk_signals(coverage_name_raw: str, text_context: str) -> List[str]:
    """
    ë¦¬ìŠ¤í¬ ì‹œê·¸ë„ ê°ì§€

    ë¦¬ìŠ¤í¬ íŒ¨í„´:
    - ê²°í•©í˜• ë‹´ë³´ëª…: "Â·", "ë°", "/", "ì‚¬ë§Â·í›„ìœ ", "ìˆ˜ìˆ Â·ì…ì›"
    - ì˜ˆì‹œ/ëŒ€í‘œê³„ì•½/ì°¸ê³  í‚¤ì›Œë“œ (denylist íšŒí”¼ ê²€ì¦)
    """
    signals = []

    # ê²°í•©í˜• íŒ¨í„´
    combined_patterns = ['Â·', 'ë°', '/', 'ì‚¬ë§Â·í›„ìœ ', 'í›„ìœ ì¥í•´Â·', 'ìˆ˜ìˆ Â·ì…ì›', 'ì…ì›Â·ìˆ˜ìˆ ']
    for pattern in combined_patterns:
        if pattern in coverage_name_raw:
            signals.append(f'COMBINED_PATTERN:{pattern}')

    # ì˜ˆì‹œ/ëŒ€í‘œ/ì°¸ê³  í‚¤ì›Œë“œ
    denylist_keywords = ['ì˜ˆì‹œ', 'ëŒ€í‘œê³„ì•½', 'ì°¸ê³ ', 'ìƒ˜í”Œ', 'í‘œì¤€']
    for kw in denylist_keywords:
        if kw in text_context:
            signals.append(f'DENYLIST_KEYWORD:{kw}')

    return signals


def extract_gt_pairs_from_proposal(proposal_page_jsonl: Path) -> List[GTAmountPair]:
    """
    ê°€ì…ì„¤ê³„ì„œ page.jsonlì—ì„œ GT í˜ì–´ ì¶”ì¶œ

    í…Œì´ë¸” êµ¬ì¡° íŒ¨í„´:
    ë‹´ë³´ê°€ì…í˜„í™©       ê°€ì…ê¸ˆì•¡    ë³´í—˜ë£Œ(ì›)  ë‚©ì…ê¸°ê°„/ë³´í—˜ê¸°ê°„
    ë‹´ë³´ëª…             ê¸ˆì•¡        ë³´í—˜ë£Œ      ê¸°ê°„
    """
    gt_pairs = []

    if not proposal_page_jsonl.exists():
        print(f"[WARN] Proposal file not found: {proposal_page_jsonl}")
        return gt_pairs

    with open(proposal_page_jsonl, 'r', encoding='utf-8') as f:
        for line_idx, line in enumerate(f):
            if not line.strip():
                continue
            try:
                page_data = json.loads(line)
                page_num = page_data.get('page', line_idx + 1)
                text = page_data.get('text', '')

                # í›„ë³´ í˜ì´ì§€ í•„í„°ë§ (í…Œì´ë¸” í‚¤ì›Œë“œ)
                if not any(kw in text for kw in ['ë³´ì¥ëª…', 'ê°€ì…ê¸ˆì•¡', 'ë³´ì¥ê¸ˆì•¡', 'ë‹´ë³´ëª…', 'ë‹´ë³´ê°€ì…í˜„í™©', 'ë‹´ë³´ë³„ ë³´ì¥ë‚´ìš©']):
                    continue

                # ë¼ì¸ ë‹¨ìœ„ë¡œ ë¶„í•´
                lines = text.split('\n')
                i = 0
                while i < len(lines):
                    line_text = lines[i].strip()
                    i += 1

                    # í—¤ë” ë¼ì¸ ìŠ¤í‚µ
                    if any(hdr in line_text for hdr in ['ë‹´ë³´ê°€ì…í˜„í™©', 'ê°€ì…ê¸ˆì•¡', 'ë³´í—˜ë£Œ', 'ë‚©ì…ê¸°ê°„', 'ë³´í—˜ê¸°ê°„', 'ë‹´ë³´ë³„ ë³´ì¥ë‚´ìš©', 'í”¼ë³´í—˜ì', 'ì„ íƒê³„ì•½', 'ê¸°ë³¸ê³„ì•½']):
                        continue

                    # ë¹ˆ ë¼ì¸, ì§§ì€ ë¼ì¸ ìŠ¤í‚µ
                    if len(line_text) < 3:
                        continue

                    # ê¸ˆì•¡ íŒ¨í„´ ì²´í¬
                    amount = extract_amount_from_text(line_text)

                    if amount:
                        # Case 1: ë‹´ë³´ëª…ê³¼ ê¸ˆì•¡ì´ ê°™ì€ ë¼ì¸ì— ìˆìŒ
                        # ì˜ˆ: "ì•” ì§„ë‹¨ë¹„(ìœ ì‚¬ì•” ì œì™¸)\n3,000ë§Œì›\n40,620\n20ë…„ë‚© 100ì„¸ë§Œê¸°\nZD8200010"
                        # ë˜ëŠ”: "ì•” ì§„ë‹¨ë¹„(ìœ ì‚¬ì•” ì œì™¸) 3,000ë§Œì› 40,620 20ë…„ë‚© 100ì„¸ë§Œê¸°"

                        # ê¸ˆì•¡ ì œê±°í•˜ì—¬ ë‹´ë³´ëª… ì¶”ì¶œ
                        coverage_candidate = re.sub(r'\d{1,3}(?:,\d{3})*ë§Œ?ì›', '', line_text)
                        coverage_candidate = re.sub(r'\d+[ì²œë°±ì‹­]ë§Œ?ì›', '', coverage_candidate)
                        coverage_candidate = re.sub(r'\d+', '', coverage_candidate).strip()

                        if len(coverage_candidate) >= 3:
                            gt_pairs.append(GTAmountPair(
                                coverage_name_raw=coverage_candidate,
                                amount_raw=amount,
                                page_num=page_num,
                                line_text=line_text
                            ))
                    else:
                        # Case 2: ë‹´ë³´ëª…ê³¼ ê¸ˆì•¡ì´ ë‹¤ë¥¸ ë¼ì¸ì— ìˆìŒ (í…Œì´ë¸” row spanning)
                        # í˜„ì¬ ë¼ì¸ì´ ë‹´ë³´ëª… í›„ë³´ì´ê³ , ë‹¤ìŒ ë¼ì¸ì´ ê¸ˆì•¡ì¸ ê²½ìš°
                        if i < len(lines):
                            next_line = lines[i].strip()
                            next_amount = extract_amount_from_text(next_line)

                            if next_amount:
                                # í˜„ì¬ ë¼ì¸ì„ ë‹´ë³´ëª…ìœ¼ë¡œ ê°„ì£¼
                                coverage_candidate = line_text

                                # ìˆ«ìë§Œ ìˆëŠ” ë¼ì¸ ì œì™¸ (ë³´í—˜ë£Œ ë¼ì¸ ë“±)
                                if re.match(r'^[\d,\s]+$', coverage_candidate):
                                    continue

                                # ë‹´ë³´ëª… ê²€ì¦ (í•œê¸€ í¬í•¨ ì—¬ë¶€)
                                if not re.search(r'[ê°€-í£]', coverage_candidate):
                                    continue

                                if len(coverage_candidate) >= 3:
                                    gt_pairs.append(GTAmountPair(
                                        coverage_name_raw=coverage_candidate,
                                        amount_raw=next_amount,
                                        page_num=page_num,
                                        line_text=f"{coverage_candidate} / {next_line}"
                                    ))
                                    i += 1  # ë‹¤ìŒ ë¼ì¸ ìŠ¤í‚µ (ì´ë¯¸ ì²˜ë¦¬ë¨)

            except json.JSONDecodeError:
                continue

    return gt_pairs


def map_gt_to_coverage_code(
    gt_pairs: List[GTAmountPair],
    scope_mapped_csv: Path
) -> List[MappingResult]:
    """GT ë‹´ë³´ëª… â†’ coverage_code ë§¤í•‘ (scope_mapped.csv ê²½ìœ )"""
    # Load scope_mapped.csv
    code_map = {}  # normalized_name -> (coverage_code, mapping_status)

    if not scope_mapped_csv.exists():
        print(f"[WARN] scope_mapped.csv not found: {scope_mapped_csv}")
        return []

    with open(scope_mapped_csv, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            raw_name = row.get('coverage_name_raw', '')
            code = row.get('coverage_code', '')
            status = row.get('mapping_status', '')

            if raw_name and code and status == 'matched':
                norm = normalize_coverage_name(raw_name)
                code_map[norm] = (code, status)

    # Map GT pairs
    results = []
    for gt in gt_pairs:
        norm = normalize_coverage_name(gt.coverage_name_raw)
        if norm in code_map:
            code, status = code_map[norm]
            results.append(MappingResult(
                gt_pair=gt,
                coverage_code=code,
                mapping_status=status,
                normalized_name=norm
            ))
        else:
            results.append(MappingResult(
                gt_pair=gt,
                coverage_code=None,
                mapping_status='unmatched',
                normalized_name=norm
            ))

    return results


def load_step7_cards(coverage_cards_jsonl: Path) -> Dict[str, dict]:
    """Step7 coverage_cards.jsonl ë¡œë“œ (coverage_code -> card)"""
    cards = {}
    if not coverage_cards_jsonl.exists():
        return cards

    with open(coverage_cards_jsonl, 'r', encoding='utf-8') as f:
        for line in f:
            if not line.strip():
                continue
            card = json.loads(line)
            code = card.get('coverage_code', '')
            if code:
                cards[code] = card
    return cards


def normalize_amount_for_comparison(amount_str: str) -> str:
    """
    ê¸ˆì•¡ ì •ê·œí™” (ë¹„êµìš©)

    ëª©ì : GTì™€ Step7ì˜ í‘œê¸° ì°¨ì´ë¥¼ í¡ìˆ˜
    - 1ì²œë§Œì› â†’ 1000ë§Œì›
    - 5ë°±ë§Œì› â†’ 500ë§Œì›
    - 2ì‹­ë§Œì› â†’ 20ë§Œì›
    - 1,000ë§Œì› â†’ 1000ë§Œì›
    """
    if not amount_str:
        return ''

    # ê³µë°±/ì‰¼í‘œ ì œê±°
    norm = re.sub(r'[\s,]', '', amount_str)

    # í•œê¸€ ìˆ«ì ë³€í™˜ (ì²œë°±ì‹­ â†’ ìˆ«ì)
    korean_nums = {
        'ì²œ': '1000',
        'ë°±': '100',
        'ì‹­': '10'
    }

    for kor, num in korean_nums.items():
        # Nì²œ â†’ N*1000 (ì˜ˆ: 3ì²œ â†’ 3000)
        pattern = rf'(\d+){kor}'
        def replace_korean(m):
            return str(int(m.group(1)) * int(num))
        norm = re.sub(pattern, replace_korean, norm)

    return norm


def check_gt_policy_issue(
    coverage_code: str,
    gt_coverage_name: str,
    gt_amount: str,
    step7_value: str,
    mapping_results: List[MappingResult],
    proposal_file: str
) -> tuple[bool, str]:
    """
    GT_POLICY_ISSUE íŒì •: GTì™€ Step7 ê°„ ì •ì±…ì  ì°¨ì´ë¡œ ì¸í•œ ë¶ˆì¼ì¹˜

    Case 1: ê²°í•©í˜• vs ë‹¨ë…í˜• ìš°ì„ ìˆœìœ„
    - ê°€ì…ì„¤ê³„ì„œì— "ìƒí•´ì‚¬ë§Â·í›„ìœ ì¥í•´" (1ë°±ë§Œì›, ë¼ì¸1)ì™€ "ìƒí•´ì‚¬ë§" (1ì²œë§Œì›, ë¼ì¸3) ëª¨ë‘ ì¡´ì¬
    - Step7ì€ ë¨¼ì € ë‚˜ì˜¤ëŠ” ê²°í•©í˜•ì„ ì„ íƒ (1ë°±ë§Œì›)
    - GTëŠ” ë‹¨ë…í˜•ì„ ì„ íƒ (1ì²œë§Œì›)
    - ì´ ê²½ìš° GT_POLICY_ISSUEë¡œ ë¶„ë¥˜í•˜ê³ , ë³„ë„ í•´ê²° ì •ì±… í•„ìš”

    Returns:
        (is_policy_issue: bool, reason: str)
    """
    # Case 1: ê²°í•©í˜• íŒ¨í„´ ì²´í¬ (Â·, ë°, /)
    combined_patterns = ['Â·', 'ë°', '/']
    has_combined_pattern = any(p in gt_coverage_name for p in combined_patterns)

    # Step7ì´ GTë³´ë‹¤ ì‘ì€ ê¸ˆì•¡ì„ ì„ íƒí•œ ê²½ìš° + GTì— ê²°í•©í˜• íŒ¨í„´ì´ ì—†ëŠ” ê²½ìš°
    # â†’ ê°€ì…ì„¤ê³„ì„œì— ê²°í•©í˜•ì´ ìˆì—ˆì§€ë§Œ GTê°€ ëª» ì°¾ì€ ê²ƒìœ¼ë¡œ ì¶”ì •
    if not has_combined_pattern and step7_value and gt_amount:
        gt_norm = normalize_amount_for_comparison(gt_amount)
        step7_norm = normalize_amount_for_comparison(step7_value)

        # Extract numeric values for comparison
        import re
        gt_num_match = re.search(r'(\d+)ë§Œì›', gt_norm)
        step7_num_match = re.search(r'(\d+)ë§Œì›', step7_norm)

        if gt_num_match and step7_num_match:
            gt_num = int(gt_num_match.group(1))
            step7_num = int(step7_num_match.group(1))

            # Step7 chose a smaller amount (likely from combined coverage line)
            if step7_num < gt_num and step7_num > 0:
                return True, f'COMBINED_VS_SEPARATE:GTì„ íƒ={gt_amount}(ë‹¨ë…),STEP7ì„ íƒ={step7_value}(ê²°í•©í˜•ì¶”ì •)'

    # Case 2: ê°™ì€ codeê°€ GTì— ì—¬ëŸ¬ ë²ˆ ë“±ì¥ + ì„œë¡œ ë‹¤ë¥¸ ê¸ˆì•¡
    same_code_mappings = [
        m for m in mapping_results
        if m.coverage_code == coverage_code and m.gt_pair.line_text
    ]

    if len(same_code_mappings) > 1:
        amounts = set(m.gt_pair.amount_raw for m in same_code_mappings)
        if len(amounts) > 1:
            return True, f'GT_DUPLICATE:ê°™ì€ì½”ë“œê°€{len(same_code_mappings)}íšŒë“±ì¥,ê¸ˆì•¡={amounts}'

    return False, ''


def compare_gt_vs_step7(
    mapping_results: List[MappingResult],
    step7_cards: Dict[str, dict],
    insurer_type: str,
    proposal_file: str
) -> List[ComparisonResult]:
    """GT vs Step7 amount ë¹„êµ"""
    comparisons = []

    for mapping in mapping_results:
        if mapping.coverage_code is None:
            # SCOPE_OR_MAPPING_GAP
            continue

        code = mapping.coverage_code
        gt_amount = mapping.gt_pair.amount_raw
        gt_coverage_name = mapping.gt_pair.coverage_name_raw
        gt_line = mapping.gt_pair.line_text

        # ë¦¬ìŠ¤í¬ ì‹œê·¸ë„ ê°ì§€
        risk_signals = detect_risk_signals(gt_coverage_name, gt_line)

        card = step7_cards.get(code)
        if not card:
            # Step7ì— ì¹´ë“œê°€ ì—†ìŒ (ì´ìƒ)
            comparisons.append(ComparisonResult(
                coverage_code=code,
                gt_amount_raw=gt_amount,
                step7_value_text=None,
                step7_status=None,
                step7_source_priority=None,
                step7_source_doc_type=None,
                step7_source_page=None,
                step7_evidence_snippet=None,
                verdict='MISS_STEP7_CARD',
                gt_page=mapping.gt_pair.page_num,
                gt_line=mapping.gt_pair.line_text,
                proposal_file=proposal_file,
                risk_signals=risk_signals
            ))
            continue

        amount_field = card.get('amount', {})
        step7_value = amount_field.get('value_text')
        step7_status = amount_field.get('status')
        step7_priority = amount_field.get('source_priority')
        step7_doc_type = amount_field.get('source_doc_type')

        # Extract evidence snippet from Step7
        evidence = amount_field.get('evidence', {})
        step7_snippet = evidence.get('snippet', '')[:200] if evidence else ''
        step7_page = evidence.get('page_num') if evidence else None

        # ì •ê·œí™” ë¹„êµ (í•œê¸€ìˆ«ì ë³€í™˜ í¬í•¨)
        gt_norm = normalize_amount_for_comparison(gt_amount)
        step7_norm = normalize_amount_for_comparison(step7_value)

        # GT_POLICY_ISSUE ì²´í¬
        is_policy_issue, policy_reason = check_gt_policy_issue(
            code, gt_coverage_name, gt_amount, step7_value, mapping_results, proposal_file
        )

        # Verdict íŒì •
        if is_policy_issue:
            verdict = 'GT_POLICY_ISSUE'
            risk_signals.append(policy_reason)
        elif step7_status == 'UNCONFIRMED' or not step7_value:
            if insurer_type == 'C':
                verdict = 'TYPE_C_EXPECTED_UNCONFIRMED'
            else:
                verdict = 'MISS_PATTERN'
        elif gt_norm == step7_norm:
            verdict = 'OK_MATCH'
        else:
            verdict = 'MISMATCH_VALUE'
            risk_signals.append(f'VALUE_DIFF:GT={gt_norm},STEP7={step7_norm}')

        comparisons.append(ComparisonResult(
            coverage_code=code,
            gt_amount_raw=gt_amount,
            step7_value_text=step7_value,
            step7_status=step7_status,
            step7_source_priority=step7_priority,
            step7_source_doc_type=step7_doc_type,
            step7_source_page=step7_page,
            step7_evidence_snippet=step7_snippet,
            verdict=verdict,
            gt_page=mapping.gt_pair.page_num,
            gt_line=mapping.gt_pair.line_text,
            proposal_file=proposal_file,
            risk_signals=risk_signals
        ))

    return comparisons


def audit_insurer_file_level(
    insurer: str,
    proposal_file: Path,
    data_root: Path,
    type_map: Dict[str, str],
    step7_cards: Dict[str, dict]
) -> dict:
    """ê°€ì…ì„¤ê³„ì„œ íŒŒì¼ ë‹¨ìœ„ ì „ìˆ˜ ì¡°ì‚¬"""
    print(f"  [File] {proposal_file.name}")

    # Step 1: Extract GT pairs
    gt_pairs = extract_gt_pairs_from_proposal(proposal_file)
    print(f"    â†’ Found {len(gt_pairs)} GT pairs")

    # Step 2: Map to coverage_code
    scope_mapped_csv = data_root / 'scope' / f'{insurer}_scope_mapped.csv'
    mapping_results = map_gt_to_coverage_code(gt_pairs, scope_mapped_csv)

    matched = [m for m in mapping_results if m.mapping_status == 'matched']
    unmatched = [m for m in mapping_results if m.mapping_status == 'unmatched']
    print(f"    â†’ Matched: {len(matched)}, Unmatched: {len(unmatched)}")

    # Step 3: Compare
    insurer_type = type_map.get(insurer, 'UNKNOWN')
    comparisons = compare_gt_vs_step7(matched, step7_cards, insurer_type, proposal_file.name)

    # Verdict ì§‘ê³„
    verdict_counts = defaultdict(int)
    risk_count = 0
    for comp in comparisons:
        verdict_counts[comp.verdict] += 1
        if comp.risk_signals:
            risk_count += 1

    print(f"    â†’ Verdicts: {dict(verdict_counts)}")
    print(f"    â†’ Risk signals: {risk_count}")

    return {
        'proposal_file': proposal_file.name,
        'gt_pairs': len(gt_pairs),
        'mapped_codes': len(matched),
        'unmatched': len(unmatched),
        'verdict_counts': dict(verdict_counts),
        'risk_count': risk_count,
        'comparisons': [asdict(c) for c in comparisons],
        'mapping_results': [asdict(m) for m in mapping_results]
    }


def audit_insurer(
    insurer: str,
    data_root: Path,
    type_map: Dict[str, str]
) -> dict:
    """ë³´í—˜ì‚¬ë³„ ì „ìˆ˜ ì¡°ì‚¬ (íŒŒì¼ ë‹¨ìœ„ë¡œ ë¶„ë¦¬)"""
    print(f"\n{'='*60}")
    print(f"[AUDIT] {insurer.upper()}")
    print(f"{'='*60}")

    # Paths
    proposal_dir = data_root / 'evidence_text' / insurer / 'ê°€ì…ì„¤ê³„ì„œ'
    proposal_files = list(proposal_dir.glob('*.page.jsonl')) if proposal_dir.exists() else []

    if not proposal_files:
        print(f"[ERROR] No proposal files found for {insurer}")
        return {
            'insurer': insurer,
            'type': type_map.get(insurer, 'UNKNOWN'),
            'error': 'NO_PROPOSAL_FILES'
        }

    # Load Step7 cards (ê³µí†µ)
    print(f"[1/2] Loading Step7 coverage_cards...")
    coverage_cards_jsonl = data_root / 'compare' / f'{insurer}_coverage_cards.jsonl'
    step7_cards = load_step7_cards(coverage_cards_jsonl)
    print(f"  â†’ Loaded {len(step7_cards)} Step7 cards")

    # File-level audit
    print(f"[2/2] Auditing {len(proposal_files)} proposal file(s)...")
    file_results = []
    for pfile in sorted(proposal_files):
        file_result = audit_insurer_file_level(insurer, pfile, data_root, type_map, step7_cards)
        file_results.append(file_result)

    # Aggregate results
    total_gt_pairs = sum(fr['gt_pairs'] for fr in file_results)
    total_mapped = sum(fr['mapped_codes'] for fr in file_results)
    total_unmatched = sum(fr['unmatched'] for fr in file_results)
    total_risk = sum(fr['risk_count'] for fr in file_results)

    aggregate_verdicts = defaultdict(int)
    all_comparisons = []
    all_mappings = []
    for fr in file_results:
        for verdict, count in fr['verdict_counts'].items():
            aggregate_verdicts[verdict] += count
        all_comparisons.extend(fr['comparisons'])
        all_mappings.extend(fr['mapping_results'])

    print(f"\n[AGGREGATE RESULTS]")
    print(f"  Total GT pairs: {total_gt_pairs}")
    print(f"  Total mapped: {total_mapped}")
    print(f"  Total risk signals: {total_risk}")
    for verdict, count in sorted(aggregate_verdicts.items()):
        print(f"  {verdict}: {count}")

    return {
        'insurer': insurer,
        'type': type_map.get(insurer, 'UNKNOWN'),
        'gt_pairs': total_gt_pairs,
        'mapped_codes': total_mapped,
        'unmatched': total_unmatched,
        'step7_cards': len(step7_cards),
        'verdict_counts': dict(aggregate_verdicts),
        'risk_count': total_risk,
        'file_results': file_results,
        'comparisons': all_comparisons,
        'mapping_results': all_mappings
    }


def generate_consolidated_report(
    audit_results: List[dict],
    output_md: Path,
    output_json: Path
):
    """í†µí•© ë¦¬í¬íŠ¸ ìƒì„± (íŒŒì¼ ë‹¨ìœ„ + ë¦¬ìŠ¤í¬ ìƒ˜í”Œë§ í¬í•¨)"""
    lines = []
    lines.append("# STEP NEXT-10B-2G-2 â€” Step7 Amount ì „ìˆ˜ ì¡°ì‚¬ í†µí•© ë¦¬í¬íŠ¸ (File-Level + Risk Sampling)\n")
    lines.append(f"**ìƒì„±ì¼**: {output_json.name}\n")
    lines.append("## 1. í†µí•© í…Œì´ë¸”\n")
    lines.append("| insurer | type | GT_pairs | mapped_codes | OK_MATCH | MISS_PATTERN | MISMATCH_VALUE | GT_POLICY_ISSUE | RISK_SIGNALS | PASS/FAIL |")
    lines.append("|---------|------|----------|--------------|----------|--------------|----------------|-----------------|--------------|-----------|")

    for result in audit_results:
        if 'error' in result:
            lines.append(f"| {result['insurer']} | {result.get('type', 'N/A')} | ERROR | - | - | - | - | - | - | FAIL |")
            continue

        insurer = result['insurer']
        itype = result['type']
        gt_pairs = result['gt_pairs']
        mapped = result['mapped_codes']
        verdicts = result['verdict_counts']
        risk_count = result.get('risk_count', 0)

        ok_match = verdicts.get('OK_MATCH', 0)
        miss_pattern = verdicts.get('MISS_PATTERN', 0)
        mismatch_value = verdicts.get('MISMATCH_VALUE', 0)
        gt_policy_issue = verdicts.get('GT_POLICY_ISSUE', 0)
        type_c_unconf = verdicts.get('TYPE_C_EXPECTED_UNCONFIRMED', 0)

        # PASS/FAIL íŒì • (GT_POLICY_ISSUEëŠ” STOP ì¡°ê±´ì—ì„œ ì œì™¸)
        fail_reasons = []

        # Type A/B: MISMATCH_VALUE > 0 ì¦‰ì‹œ FAIL
        if itype in ['A', 'B'] and mismatch_value > 0:
            fail_reasons.append(f'MISMATCH_VALUE={mismatch_value}')

        # Type A: MISS_PATTERN ë¹„ìœ¨ > 5%
        if itype == 'A' and mapped > 0:
            miss_ratio = miss_pattern / mapped
            if miss_ratio > 0.05:
                fail_reasons.append(f'MISS_PATTERN_RATIO={miss_ratio:.1%}')

        # Type C: "ë³´í—˜ê°€ì…ê¸ˆì•¡" ë¬¸êµ¬ ì²´í¬ (ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ MISMATCH_VALUEë¡œ ëŒ€ì²´)
        if itype == 'C' and mismatch_value > 0:
            fail_reasons.append(f'TYPE_C_MISMATCH={mismatch_value}')

        pass_fail = 'FAIL' if fail_reasons else 'PASS'

        lines.append(
            f"| {insurer} | {itype} | {gt_pairs} | {mapped} | "
            f"{ok_match} | {miss_pattern} | {mismatch_value} | {gt_policy_issue} | {risk_count} | {pass_fail} |"
        )

    lines.append("\n## 2. PASS/FAIL ê¸°ì¤€ (GT_POLICY_ISSUEëŠ” STOP ì¡°ê±´ì—ì„œ ì œì™¸)\n")
    lines.append("- **Type A**:")
    lines.append("  - MISMATCH_VALUE > 0 â†’ FAIL/STOP")
    lines.append("  - MISS_PATTERN / mapped_codes > 5% â†’ FAIL (íŒ¨í„´/ë ˆì´ì•„ì›ƒ ìˆ˜ì • í•„ìš”)")
    lines.append("- **Type B**:")
    lines.append("  - MISMATCH_VALUE > 0 â†’ FAIL/STOP")
    lines.append("- **Type C**:")
    lines.append("  - UNCONFIRMED ë¹„ìœ¨ ë†’ì•„ë„ ì •ìƒ")
    lines.append("  - ë‹¨, \"ë³´í—˜ê°€ì…ê¸ˆì•¡\" ë¬¸êµ¬ê°€ amount.value_textì— ë“¤ì–´ê°€ë©´ FAIL/STOP")
    lines.append("- **GT_POLICY_ISSUE (STOP ì¡°ê±´ ì œì™¸)**:")
    lines.append("  - Case 1: ê²°í•©í˜• vs ë‹¨ë…í˜• ìš°ì„ ìˆœìœ„ ì°¨ì´")
    lines.append("    - ê°€ì…ì„¤ê³„ì„œì— 'ìƒí•´ì‚¬ë§Â·í›„ìœ ì¥í•´'(1ë°±ë§Œì›, ë¼ì¸1)ì™€ 'ìƒí•´ì‚¬ë§'(1ì²œë§Œì›, ë¼ì¸3) ëª¨ë‘ ì¡´ì¬")
    lines.append("    - Step7ì€ ë¨¼ì € ë‚˜ì˜¤ëŠ” ê²°í•©í˜• ì„ íƒ (í˜ì´ì§€ ìˆœì„œ ê¸°ì¤€)")
    lines.append("    - GTëŠ” ë‹¨ë…í˜• ì„ íƒ (ë§¤í•‘ ì •ê·œí™” ê¸°ì¤€)")
    lines.append("    - â†’ ì •ì±…ì  ì°¨ì´ì´ë¯€ë¡œ MISMATCHë¡œ ì¹´ìš´íŠ¸í•˜ì§€ ì•ŠìŒ")
    lines.append("  - Case 2: GTì—ì„œ ê°™ì€ ì½”ë“œê°€ ì—¬ëŸ¬ íŒŒì¼/í˜ì´ì§€ì— ì¤‘ë³µ ë“±ì¥ + ì„œë¡œ ë‹¤ë¥¸ ê¸ˆì•¡")
    lines.append("    - â†’ GT ì¶”ì¶œ ë¡œì§ ë¬¸ì œ ë˜ëŠ” ì •ì±… ë¯¸ì •ì˜\n")

    lines.append("\n## 3. ë³´í—˜ì‚¬ë³„ ìƒì„¸ ê²°ê³¼ (íŒŒì¼ ë‹¨ìœ„ ë¶„ë¦¬)\n")
    for result in audit_results:
        if 'error' in result:
            lines.append(f"### {result['insurer'].upper()} (ERROR)\n")
            lines.append(f"**Error**: {result['error']}\n")
            continue

        lines.append(f"### {result['insurer'].upper()} (Type {result['type']})\n")
        lines.append(f"- Total GT pairs: {result['gt_pairs']}")
        lines.append(f"- Total mapped codes: {result['mapped_codes']}")
        lines.append(f"- Total unmatched: {result['unmatched']}")
        lines.append(f"- Step7 cards: {result['step7_cards']}")
        lines.append(f"- Risk signals: {result.get('risk_count', 0)}")
        lines.append(f"- Verdict counts: {result['verdict_counts']}\n")

        # íŒŒì¼ë³„ ê²°ê³¼
        if 'file_results' in result:
            lines.append("#### íŒŒì¼ë³„ ë¶„ì„\n")
            for file_result in result['file_results']:
                lines.append(f"**{file_result['proposal_file']}**")
                lines.append(f"- GT pairs: {file_result['gt_pairs']}, Mapped: {file_result['mapped_codes']}")
                lines.append(f"- Verdicts: {file_result['verdict_counts']}")
                lines.append(f"- Risk signals: {file_result['risk_count']}\n")

        # ë¦¬ìŠ¤í¬ ìƒ˜í”Œ (MISMATCH_VALUE, GT_POLICY_ISSUE ì „ìˆ˜ ì¶œë ¥)
        comparisons = result['comparisons']
        high_risk_verdicts = ['MISMATCH_VALUE', 'GT_POLICY_ISSUE']
        for verdict in high_risk_verdicts:
            samples = [c for c in comparisons if c['verdict'] == verdict]
            if not samples:
                continue

            lines.append(f"#### ğŸš¨ {verdict} ì „ìˆ˜ ì¶œë ¥ ({len(samples)}ê±´)\n")
            for sample in samples:
                lines.append(f"- **{sample['coverage_code']}** (íŒŒì¼: {sample['proposal_file']})")
                lines.append(f"  - GT: `{sample['gt_amount_raw']}` (Page {sample['gt_page']})")
                lines.append(f"  - GT Line: `{sample['gt_line'][:150]}`")
                lines.append(f"  - Step7: `{sample['step7_value_text']}` (status={sample['step7_status']})")
                if sample.get('step7_source_page'):
                    lines.append(f"  - Step7 Page: {sample['step7_source_page']}")
                if sample.get('step7_evidence_snippet'):
                    lines.append(f"  - Step7 Snippet: `{sample['step7_evidence_snippet'][:150]}`")
                if sample.get('risk_signals'):
                    lines.append(f"  - Risk Signals: {', '.join(sample['risk_signals'])}")
                lines.append("")

        # ì¼ë°˜ ìƒ˜í”Œ (OK_MATCH, MISS_PATTERN ë“± ìµœëŒ€ 3ê°œ)
        other_verdicts = [v for v in set(c['verdict'] for c in comparisons) if v not in high_risk_verdicts]
        for verdict in sorted(other_verdicts):
            samples = [c for c in comparisons if c['verdict'] == verdict]
            lines.append(f"#### {verdict} (ìƒ˜í”Œ ìµœëŒ€ 3ê°œ)\n")
            for sample in samples[:3]:
                lines.append(f"- **{sample['coverage_code']}** (íŒŒì¼: {sample['proposal_file']})")
                lines.append(f"  - GT: `{sample['gt_amount_raw']}`")
                lines.append(f"  - Step7: `{sample['step7_value_text']}` (status={sample['step7_status']})")
                lines.append(f"  - Page {sample['gt_page']}: `{sample['gt_line'][:100]}`\n")

    # Write MD
    output_md.parent.mkdir(parents=True, exist_ok=True)
    with open(output_md, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))

    # Write JSON
    with open(output_json, 'w', encoding='utf-8') as f:
        json.dump(audit_results, f, ensure_ascii=False, indent=2)

    print(f"\n[OUTPUT]")
    print(f"  MD: {output_md}")
    print(f"  JSON: {output_json}")


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    # Paths
    repo_root = Path(__file__).parent.parent.parent
    data_root = repo_root / 'data'
    reports_dir = repo_root / 'reports'
    config_dir = repo_root / 'config'

    # Load type map
    type_map_json = config_dir / 'amount_lineage_type_map.json'
    with open(type_map_json, 'r', encoding='utf-8') as f:
        type_map = json.load(f)

    # Insurers
    insurers = ['samsung', 'meritz', 'db', 'hanwha', 'hyundai', 'kb', 'lotte', 'heungkuk']

    # Audit
    audit_results = []
    for insurer in insurers:
        result = audit_insurer(insurer, data_root, type_map)
        audit_results.append(result)

    # Generate consolidated report
    from datetime import datetime
    timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
    output_md = reports_dir / f'step7_gt_audit_all_{timestamp}.md'
    output_json = reports_dir / f'step7_gt_audit_all_{timestamp}.json'

    generate_consolidated_report(audit_results, output_md, output_json)

    # Check FAIL (GT_AMBIGUOUS ì œì™¸)
    failed = []
    for r in audit_results:
        if 'error' in r:
            failed.append((r['insurer'], f"ERROR: {r['error']}"))
        else:
            verdicts = r.get('verdict_counts', {})
            mismatch = verdicts.get('MISMATCH_VALUE', 0)
            if mismatch > 0:
                failed.append((r['insurer'], f"MISMATCH_VALUE={mismatch}"))

    if failed:
        print(f"\nâŒ AUDIT FAILED: {len(failed)} insurer(s) with issues")
        for insurer, reason in failed:
            print(f"  - {insurer}: {reason}")
        print(f"\n[NOTE] GT_AMBIGUOUSëŠ” STOP ì¡°ê±´ì—ì„œ ì œì™¸ë¨ (GT ì •ì˜ ëª¨í˜¸ì„±)")
        sys.exit(1)
    else:
        print(f"\nâœ… AUDIT PASSED: All {len(insurers)} insurers OK")
        print(f"   (GT_AMBIGUOUS ì¼€ì´ìŠ¤ëŠ” STOP ì¡°ê±´ì—ì„œ ì œì™¸ë¨)")
        sys.exit(0)


if __name__ == '__main__':
    main()
