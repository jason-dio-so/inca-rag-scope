# PIPELINE ALIGNMENT AUDIT â€” ê°€ì…ì„¤ê³„ì„œ ë‹´ë³´ ì¶”ì¶œ ì¤‘ì‹¬ êµ¬ì¡° ì¬ê²€í† 

**Date**: 2025-12-30
**Purpose**: í˜„ì¬ pipelineì´ "ê°€ì…ì„¤ê³„ì„œì—ì„œ ë‹´ë³´ ì¶”ì¶œ â†’ canonical ì •í•© â†’ ì´í›„ ì²˜ë¦¬" ëª©í‘œì™€ êµ¬ì¡°ì ìœ¼ë¡œ ì¼ì¹˜í•˜ëŠ”ì§€ ì „ë©´ ì¬ê²€í† 
**Scope**: êµ¬ì¡° ë¶„ì„ (ì½”ë“œ ìˆ˜ì • âŒ, ë‹¨ê±´ ë²„ê·¸ ìˆ˜ì • âŒ, ì„ì‹œ íŒ¨ì¹˜ ê¸ˆì§€)

---

## ğŸ¯ Executive Summary

### í•µì‹¬ ë°œê²¬
1. **ë‹´ë³´ ì •ì˜ ì£¼ì²´ ë¶„ì‚°**: ë‹´ë³´ì˜ "ì¡´ì¬"ì™€ "ì •ì²´ì„±"ì´ 3ê°œ stepì— ë¶„ì‚° (Step0/Step1 ì¶”ì¶œ, Step2 ë§¤í•‘, Step5 ì¹´ë“œ ìƒì„±)
2. **Proposal ëª…ì¹­ vs Canonical ëª…ì¹­ ê°„ê·¹**: Step2 mappingì€ **exact/normalized ì¼ì¹˜**ë§Œ ì§€ì›, alias layer ì—†ìŒ
3. **Hanwha/Heungkuk êµ¬ì¡°ì  í•œê³„**: ê°€ì…ì„¤ê³„ì„œ ëª…ì¹­ â‰  mapping ìë£Œ ëª…ì¹­ â†’ **êµ¬ì¡°ì ìœ¼ë¡œ ë§¤ì¹­ ë¶ˆê°€ëŠ¥**

### í˜„ì¬ êµ¬ì¡°ë¡œ ê°€ëŠ¥í•œ ê²ƒ
- âœ… ê°€ì…ì„¤ê³„ì„œ í…Œì´ë¸”ì—ì„œ ë‹´ë³´ëª… ì¶”ì¶œ (table-based filtering ì •ì°©)
- âœ… Mapping ìë£Œì— ë“±ë¡ëœ aliasì™€ exact/normalized ë§¤ì¹­
- âœ… Matched ë‹´ë³´ì— ëŒ€í•œ evidence ê²€ìƒ‰ + amount ì¶”ì¶œ

### í˜„ì¬ êµ¬ì¡°ë¡œ ë¶ˆê°€ëŠ¥í•œ ê²ƒ
- âŒ Mapping ìë£Œì— ì—†ëŠ” proposal ëª…ì¹­ ìë™ í•´ì„
- âŒ "4ëŒ€ìœ ì‚¬ì•”" â†” "ìœ ì‚¬ì•”(8ëŒ€)" ê°™ì€ semantic equivalence ì¶”ë¡ 
- âŒ Fuzzy matching (ì˜ë„ì  ê¸ˆì§€ by SSOT contract)

---

## 1ï¸âƒ£ Pipeline Step-by-Step Analysis

### **STEP 0: Scope Filter** (coverage_candidate_filter.py)

#### Input
- `data/evidence_text/{insurer}/ê°€ì…ì„¤ê³„ì„œ/*.page.jsonl` (PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼)

#### Output
- `data/scope/{insurer}_scope.csv` (filtered coverage candidates)

#### Decision Points
| ì§ˆë¬¸ | ë‹µë³€ |
|------|------|
| íŒë‹¨ì„ ë‚´ë¦¬ëŠ”ê°€? | **YES** - ë¬´ì—‡ì´ ë‹´ë³´ì¸ì§€ / ë¬´ì—‡ì´ ì•„ë‹Œì§€ ê²°ì • |
| Business Logic í¬í•¨? | **YES** - EXCLUSION_PATTERNS (condition sentences, explanations) |
| íšŒì‚¬ë³„ í¬ë§· ì°¨ì´ ì±…ì„? | **NO** - íŒ¨í„´ì€ ë²”ìš©, íšŒì‚¬ íŠ¹í™” ë¡œì§ ì—†ìŒ |

#### Logic Summary
```python
# Hard Rules (lines 53-74)
EXCLUSION_PATTERNS = [
    (r'(ìœ¼ë¡œ|ë¡œ)\s*ì§„ë‹¨í™•ì •ëœ\s*ê²½ìš°', 'CONDITION_SENTENCE'),  # ì¡°ê±´ë¬¸
    (r'(ì¸|í•œ)\s*ê²½ìš°$', 'CONDITION_SENTENCE'),
    (r'ì‹œ$', 'CONDITION_SENTENCE'),
    (r'ë‹¤\.$', 'SENTENCE_ENDING'),                          # ë¬¸ì¥ ì¢…ê²°
    (r'ë³´ì¥ê°œì‹œì¼\s*ì´í›„', 'EXPLANATION_PHRASE'),           # ì„¤ëª…ë¬¸
    (r'ë‚©ì…ë©´ì œëŒ€ìƒ', 'PREMIUM_WAIVER'),                    # ë¹„ë‹´ë³´
]

# Source validation (lines 100-102)
if candidate.source_type == 'paragraph':  # NOT table
    return FilterResult(candidate, False, 'NON_TABLE_SOURCE')
```

#### Key Insight
- **ë‹´ë³´ "ì¡´ì¬" 1ì°¨ íŒì •**: table rowì—ì„œ ë‚˜ì™”ê³ , condition/explanation íŒ¨í„´ ë¯¸í¬í•¨ â†’ ë‹´ë³´ í›„ë³´
- **ì •ì²´ì„± íŒì •ì€ ì•ˆ í•¨**: ì´ë¦„ë§Œ ì¶”ì¶œ, ì–´ë–¤ ë‹´ë³´ì¸ì§€ëŠ” Step2ì— ìœ„ì„

---

### **STEP 1-sanitize: Sanitize Scope** (step1_sanitize_scope/run.py)

#### Input
- `data/scope/{insurer}_scope_mapped.csv` (mapping í›„ ê²°ê³¼)

#### Output
- `data/scope/{insurer}_scope_mapped.sanitized.csv` (ì •ì œëœ scope)
- `data/scope/{insurer}_scope_filtered_out.jsonl` (ì œê±° audit trail)

#### Decision Points
| ì§ˆë¬¸ | ë‹µë³€ |
|------|------|
| íŒë‹¨ì„ ë‚´ë¦¬ëŠ”ê°€? | **YES** - ì¶”ê°€ condition sentence ì œê±° |
| Business Logic í¬í•¨? | **YES** - DROP_PATTERNS (step0ê³¼ ìœ ì‚¬í•˜ì§€ë§Œ ë” ê°•í™”) |
| íšŒì‚¬ë³„ í¬ë§· ì°¨ì´ ì±…ì„? | **NO** - ë²”ìš© íŒ¨í„´ ì ìš© |

#### Logic Summary
```python
# DROP patterns (lines 34-55)
DROP_PATTERNS = [
    (r'(ìœ¼ë¡œ|ë¡œ)\s*ì§„ë‹¨í™•ì •ëœ\s*ê²½ìš°', 'CONDITION_DIAGNOSIS'),
    (r'(ì¸|í•œ)\s*ê²½ìš°$', 'CONDITION_CASE'),
    (r'ì¼\s*ë•Œ$', 'CONDITION_WHEN'),
    (r'ì§€ê¸‰\s*(ì¡°ê±´|ì‚¬ìœ |ë‚´ìš©)', 'PAYMENT_EXPLANATION'),
    (r'ë‚©ì…ë©´ì œ.*ëŒ€ìƒ', 'PREMIUM_WAIVER'),
]

# Sentence-like unmatched filtering (lines 76-84)
if mapping_status == 'unmatched' or not coverage_code:
    if any(marker in coverage_name_raw for marker in ['~', 'ìœ¼ë¡œ', 'ëŠ”', 'ëŠ”ì§€']):
        if len(coverage_name_raw) > 20 and no_coverage_keywords:
            return True, 'SENTENCE_LIKE_UNMATCHED'
```

#### Key Insight
- **ì¤‘ë³µ í•„í„°ë§ (Step0 í›„ ì¶”ê°€)**: mapping í›„ unmatched ì¤‘ ë¬¸ì¥í˜• ì¶”ê°€ ì œê±°
- **Mapping status ì •ê·œí™”**: `.strip().lower()` ì ìš© (SSOT ì¤€ë¹„)

---

### **STEP 2: Canonical Mapping** (step2_canonical_mapping/map_to_canonical.py)

#### Input
- `data/scope/{insurer}_scope.csv` (ì¶”ì¶œëœ ë‹´ë³´ ëª©ë¡)
- `data/sources/mapping/ë‹´ë³´ëª…mappingìë£Œ.xlsx` (INPUT contract - ë‹¨ì¼ ì¶œì²˜)

#### Output
- `data/scope/{insurer}_scope_mapped.csv` (coverage_code + mapping_status ì¶”ê°€)

#### Decision Points
| ì§ˆë¬¸ | ë‹µë³€ |
|------|------|
| íŒë‹¨ì„ ë‚´ë¦¬ëŠ”ê°€? | **YES** - ë‹´ë³´ì˜ ì •ì²´ì„±(canonical code) í™•ì • |
| Business Logic í¬í•¨? | **YES** - 4-tier matching dictionary |
| íšŒì‚¬ë³„ í¬ë§· ì°¨ì´ ì±…ì„? | **PARTIAL** - Excel alias ì˜ì¡´ |

#### Logic Summary
```python
# 4-tier matching (lines 77-108)
# Tier 1: Exact match on canonical name
mapping_dict[coverage_name_canonical] = {..., 'match_type': 'exact'}

# Tier 2: Normalized match on canonical name
normalized_canonical = _normalize(coverage_name_canonical)
mapping_dict[normalized_canonical] = {..., 'match_type': 'normalized'}

# Tier 3: Exact match on insurer alias (from Excel)
mapping_dict[coverage_name_insurer] = {..., 'match_type': 'alias'}

# Tier 4: Normalized match on insurer alias
normalized_insurer = _normalize(coverage_name_insurer)
mapping_dict[normalized_insurer] = {..., 'match_type': 'normalized_alias'}

# Normalization (lines 26-40)
def _normalize(text):
    text = re.sub(r'\s+', '', text)              # ê³µë°± ì œê±°
    text = re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    return text.lower()
```

#### Key Insight
- **ë‹´ë³´ ì •ì²´ì„± í™•ì •**: coverage_code ë¶€ì—¬ = canonicalë¡œ ë§¤í•‘ ì„±ê³µ
- **Alias ì˜ì¡´ì„±**: ë³´í—˜ì‚¬ë³„ ëª…ì¹­ì€ **Excel íŒŒì¼ì— ìˆ˜ë™ ë“±ë¡ëœ ê²ƒë§Œ** ì¸ì‹
- **No fallback beyond Excel**: ì—‘ì…€ì— ì—†ìœ¼ë©´ â†’ `unmatched` (Step2ì—ì„œ íŒë‹¨ ì¢…ë£Œ)

---

### **STEP 3: Extract Text** (step3_extract_text/extract_pdf_text.py)

#### Input
- `data/evidence_sources/{insurer}_manifest.csv` (PDF ëª©ë¡)

#### Output
- `data/evidence_text/{insurer}/{doc_type}/{basename}.page.jsonl`

#### Decision Points
| ì§ˆë¬¸ | ë‹µë³€ |
|------|------|
| íŒë‹¨ì„ ë‚´ë¦¬ëŠ”ê°€? | **NO** - ë‹¨ìˆœ í…ìŠ¤íŠ¸ ì¶”ì¶œ |
| Business Logic í¬í•¨? | **NO** - PyMuPDF ë˜í¼ |
| íšŒì‚¬ë³„ í¬ë§· ì°¨ì´ ì±…ì„? | **NO** |

#### Logic Summary
```python
# Simple extraction (lines 48-61)
doc = fitz.open(pdf_path)
for page_num, page in enumerate(doc, start=1):
    text = page.get_text("text")
    page_jsonl.write(json.dumps({"page": page_num, "text": text.strip()}))
```

#### Key Insight
- **Infrastructure layer**: íŒë‹¨/í•´ì„ ì—†ìŒ, raw textë§Œ ì¶”ì¶œ

---

### **STEP 4: Evidence Search** (step4_evidence_search/search_evidence.py)

#### Input
- `data/scope/{insurer}_scope_mapped.csv` (mapped coverages)
- `data/evidence_text/{insurer}/**/*.page.jsonl` (extracted text)

#### Output
- `data/evidence_pack/{insurer}_evidence_pack.jsonl` (evidence per coverage)

#### Decision Points
| ì§ˆë¬¸ | ë‹µë³€ |
|------|------|
| íŒë‹¨ì„ ë‚´ë¦¬ëŠ”ê°€? | **YES** - ì–´ë–¤ í…ìŠ¤íŠ¸ê°€ ë‹´ë³´ evidenceì¸ì§€ ê²°ì • |
| Business Logic í¬í•¨? | **YES** - Query variants, fallback patterns |
| íšŒì‚¬ë³„ í¬ë§· ì°¨ì´ ì±…ì„? | **YES** - Hyundai/Hanwha íŠ¹í™” variants |

#### Logic Summary
```python
# Hyundai variants (lines 57-95)
def _generate_hyundai_query_variants(coverage_name):
    variants = [coverage_name]
    # Rule (a): ë suffix ì œê±° - ë‹´ë³´, íŠ¹ì•½, ë³´ì¥
    # Rule (b): ì§„ë‹¨ë¹„ â†” ì§„ë‹¨ ë³€í™˜
    return variants[:4]

# Hanwha variants (lines 97-213)
def _generate_hanwha_query_variants(coverage_name):
    variants = [coverage_name]
    # Rule (a): suffix ì œê±°
    # Rule (b): ì§„ë‹¨ë¹„ â†” ì§„ë‹¨ ë³€í™˜
    # Rule (c): ì•” ìš©ì–´ ë¸Œë¦¿ì§€ - 4ëŒ€ìœ ì‚¬ì•” â†” ìœ ì‚¬ì•”(4ëŒ€) â†” ìœ ì‚¬ì•”
    # Rule (d): Top-6 suffix variants (ì¹˜ë£Œë¹„ â†” ì¹˜ë£Œ, ì…ì›ì¼ë‹¹ â†” ì…ì›, ...)
    return variants[:6]

# Doc-type independent search (lines 492-540)
for doc_type in ['ì•½ê´€', 'ì‚¬ì—…ë°©ë²•ì„œ', 'ìƒí’ˆìš”ì•½ì„œ']:
    evidences = search_in_doc_type(coverage_name, doc_type)
    hits_by_doc_type[doc_type] = len(evidences)

# Fallback: token-AND search (lines 371-429)
if phrase_search_fails:
    tokens = extract_core_tokens(coverage_name)  # 2+ Korean chars
    find_lines_with_at_least_2_tokens()
```

#### Key Insight
- **Evidence ë°œê²¬ ì±…ì„**: Mapping ì„±ê³µ ì—¬ë¶€ì™€ ë¬´ê´€í•˜ê²Œ ì•½ê´€/ì‚¬ì—…ë°©ë²•ì„œ/ìƒí’ˆìš”ì•½ì„œì—ì„œ í…ìŠ¤íŠ¸ ì¦ê±° ê²€ìƒ‰
- **íšŒì‚¬ë³„ heuristic ì§‘ì¤‘ì§€**: Hyundai/Hanwha variant ìƒì„± ë¡œì§ ì¡´ì¬
- **Proposal ëª…ì¹­ ì‚¬ìš© ì•ˆ í•¨**: `coverage_name_canonical` ë˜ëŠ” `coverage_name_raw`ë¡œ ê²€ìƒ‰ (proposal ëª…ì¹­ ì§ì ‘ ì‚¬ìš© ì—†ìŒ)

---

### **STEP 5: Build Cards** (step5_build_cards/build_cards.py)

#### Input
- Resolved scope CSV (3-tier fallback: sanitized â†’ mapped â†’ original)
- `data/evidence_pack/{insurer}_evidence_pack.jsonl`

#### Output
- **`data/compare/{insurer}_coverage_cards.jsonl`** â† **Coverage SSOT**

#### Decision Points
| ì§ˆë¬¸ | ë‹µë³€ |
|------|------|
| íŒë‹¨ì„ ë‚´ë¦¬ëŠ”ê°€? | **YES** - SSOT ìƒì„± (ìµœì¢… ë‹´ë³´ ëª©ë¡ í™•ì •) |
| Business Logic í¬í•¨? | **YES** - Evidence diversity selection (Rule 6-Îµ.2) |
| íšŒì‚¬ë³„ í¬ë§· ì°¨ì´ ì±…ì„? | **NO** - ë²”ìš© ë¡œì§ |

#### Logic Summary
```python
# Coverage card structure (core/compare_types.py:43-67)
@dataclass
class CoverageCard:
    insurer: str
    coverage_name_raw: str            # Proposal ë‹´ë³´ëª…
    coverage_code: Optional[str]      # Canonical code (matchedë§Œ)
    coverage_name_canonical: Optional[str]
    mapping_status: str               # "matched" | "unmatched"
    evidence_status: str              # "found" | "not_found"
    evidences: List[Evidence]
    hits_by_doc_type: dict
    flags: List[str]

# Evidence diversity selection (lines 26-128)
def _select_diverse_evidences(evidences, max_count=3):
    # Dedup by (doc_type, file_path, page, snippet)
    # Fallback detection: 'fallback_' in keyword OR keyword.startswith('token_and(')
    # Priority: non-fallback > ì•½ê´€ > ì‚¬ì—…ë°©ë²•ì„œ > ìƒí’ˆìš”ì•½ì„œ > page asc
    # Diversity pass: 1 per doc_type, then fill-up to max 3
```

#### Key Insight
- **SSOT ìƒì„± ì§€ì **: ì´ ë‹¨ê³„ì—ì„œ coverage ëª©ë¡ì´ í™•ì •ë¨
- **Mapping status ë³´ì¡´**: `unmatched` ë‹´ë³´ë„ ì¹´ë“œì— í¬í•¨ (ì¦ê±°ê°€ ìˆìœ¼ë©´ evidence_status=found)
- **Proposal ëª…ì¹­ ìœ ì§€**: `coverage_name_raw`ëŠ” ê°€ì…ì„¤ê³„ì„œ ì›ë³¸ ëª…ì¹­ ê·¸ëŒ€ë¡œ ì €ì¥

---

### **STEP 7: Amount Extraction** (step7_amount_extraction/extract_and_enrich_amounts.py)

#### Input
- `data/compare/{insurer}_coverage_cards.jsonl`
- `data/evidence_text/{insurer}/ê°€ì…ì„¤ê³„ì„œ/*.page.jsonl`

#### Output
- **`data/compare/{insurer}_coverage_cards.jsonl`** (enriched with `amount` field)

#### Decision Points
| ì§ˆë¬¸ | ë‹µë³€ |
|------|------|
| íŒë‹¨ì„ ë‚´ë¦¬ëŠ”ê°€? | **YES** - ê¸ˆì•¡ í™•ì • (CONFIRMED/UNCONFIRMED) |
| Business Logic í¬í•¨? | **YES** - Normalization + amount pattern extraction |
| íšŒì‚¬ë³„ í¬ë§· ì°¨ì´ ì±…ì„? | **YES** - Multi-line merging (Hanwha/Heungkuk) |

#### Logic Summary
```python
# Coverage name normalization for matching (lines 59-94)
def normalize_coverage_name_for_matching(raw_name):
    # 1. Remove line number prefixes: ^\d{2,}\s+ OR ^\d{1,2}\.\s+
    normalized = re.sub(r'^(\d{2,}\s+|\d{1,2}\.\s+)', '', raw_name)

    # 2. Extract from base contract: ê¸°ë³¸ê³„ì•½(ë‹´ë³´ëª…) â†’ ë‹´ë³´ëª…
    base_contract_match = re.search(r'^ê¸°ë³¸ê³„ì•½\(([^)]+)\)', normalized)
    if base_contract_match:
        normalized = base_contract_match.group(1)

    # 3. Remove whitespace/special chars
    normalized = re.sub(r'\s+', '', normalized)
    normalized = re.sub(r'[Â·\-_...]', '', normalized)

    return normalized.strip()

# Multi-line amount merging (lines 162-192 STEP NEXT-19)
def merge_amount_fragments(lines, start_idx):
    # Pattern: "1," + "000ë§Œì›" â†’ "1,000ë§Œì›"
    comma_match = re.fullmatch(r'(\d+),', first_line)
    if comma_match and next_line_matches_NNNë§Œì›:
        merged = f"{comma_match.group(1)},{unit_match.group(1)}{unit_match.group(2)}"
        return merged, 2  # consumed 2 lines

# Matching to coverage_code (lines 322-366)
def match_proposal_to_coverage_code(pairs, scope_mapped_csv):
    # Normalize both proposal and scope names
    # Match normalized names â†’ coverage_code
    # First match only (no duplicates)
```

#### Key Insight
- **Proposal ë‹´ë³´ëª… ì§ì ‘ ì‚¬ìš©**: ê°€ì…ì„¤ê³„ì„œì—ì„œ ì¶”ì¶œí•œ `(ë‹´ë³´ëª…, ê¸ˆì•¡)` í˜ì–´ì˜ ë‹´ë³´ëª…ì„ **normalize í›„ scope_mapped.csvì™€ ë§¤ì¹­**
- **Matching ì§€ì  2íšŒ ë°œìƒ**:
  1. Step2: `coverage_name_raw` (ê°€ì…ì„¤ê³„ì„œ) â†’ canonical code
  2. Step7: proposal í˜ì–´ ë‹´ë³´ëª… â†’ scope `coverage_name_raw` â†’ canonical code
- **Step7 matchingì€ Step2ì™€ ë…ë¦½ì **: Step2 ì‹¤íŒ¨í•´ë„ Step7ì—ì„œ ì¬ì‹œë„ (ì •ê·œí™” ê·œì¹™ ë‹¤ë¦„)

---

## 2ï¸âƒ£ ë‹´ë³´ ì¶”ì¶œ ê´€ì  í•µì‹¬ ì§ˆë¬¸ ë‹µë³€

### Q1: "ë‹´ë³´ì˜ ì¡´ì¬"ëŠ” ì–´ëŠ stepì—ì„œ í™•ì •ë˜ëŠ”ê°€?

**Answer**: **Step0 + Step5 ì¡°í•©**

1. **Step0 (1ì°¨ ì¡´ì¬ íŒì •)**: ê°€ì…ì„¤ê³„ì„œ table rowì—ì„œ ì¶”ì¶œ, condition sentence ì•„ë‹˜ â†’ ë‹´ë³´ í›„ë³´
2. **Step1-sanitize (2ì°¨ ì •ì œ)**: mapping í›„ unmatched ì¤‘ ë¬¸ì¥í˜• ì¶”ê°€ ì œê±°
3. **Step5 (ìµœì¢… í™•ì •)**: Coverage card SSOT ìƒì„± = ë‹´ë³´ ì¡´ì¬ í™•ì • (matchedë“  unmatchedë“ )

**ë¬¸ì œì **:
- Step0-1-5ê°€ "ì¡´ì¬" íŒì •ì„ ë¶„ì‚° ìˆ˜í–‰
- Step5ëŠ” ì´ë¯¸ Step2 mapping ê²°ê³¼ë¥¼ ë°›ì€ ìƒíƒœ â†’ **unmatchedëŠ” Step5ì—ì„œ ì œê±° ë¶ˆê°€** (SSOTì— í¬í•¨ë¨)

---

### Q2: "ë‹´ë³´ì˜ ì •ì²´ì„±(ì–´ë–¤ ë‹´ë³´ì¸ê°€)"ì€ ì–´ëŠ stepì—ì„œ í™•ì •ë˜ëŠ”ê°€?

**Answer**: **Step2 (Canonical Mapping)** ë‹¨ë…

- **Step2 ì„±ê³µ (matched)**: coverage_code ë¶€ì—¬ â†’ canonical ì •ì²´ì„± í™•ì •
- **Step2 ì‹¤íŒ¨ (unmatched)**: ì •ì²´ì„± ë¯¸í™•ì • â†’ ì´í›„ ëª¨ë“  stepì—ì„œ `coverage_code=None` ìœ ì§€

**ë¬¸ì œì **:
- Step2 ì´í›„ **ì¬íŒì • ê¸°íšŒ ì—†ìŒ** (Step7 amount matchingì€ ë³„ë„ ë¡œì§, canonical code ì¬ë¶€ì—¬ ì•ˆ í•¨)
- Unmatched ë‹´ë³´ëŠ” ì˜êµ¬ì ìœ¼ë¡œ ì •ì²´ì„± ì—†ì´ íë¦„

---

### Q3: "Canonical codeë¡œì˜ ê·€ì†"ì€ ì–´ëŠ stepì—ì„œ í™•ì •ë˜ëŠ”ê°€?

**Answer**: **Step2 (Canonical Mapping) ë‹¨ë…**

- Mapping ìë£Œ Excelì˜ 4-tier dictionary lookup ê²°ê³¼ê°€ ì „ë¶€
- Tier 1-4 ëª¨ë‘ ì‹¤íŒ¨ â†’ `unmatched` (ì´í›„ ë³€ê²½ ë¶ˆê°€)

**ë¬¸ì œì **:
- Excel íŒŒì¼ì— alias ë“±ë¡ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´ **êµ¬ì¡°ì ìœ¼ë¡œ ë§¤ì¹­ ë¶ˆê°€**
- Step4 evidence search / Step7 amount extractionì€ canonical code ì¬ë¶€ì—¬ ê¶Œí•œ ì—†ìŒ

---

### Q4: Scope mismatch / ëª…ì¹­ ë¶ˆì¼ì¹˜ëŠ” ì–´ëŠ ë¬¸ì œì¸ê°€?

**Answer**: **Mapping ë¬¸ì œ + Alias ì •ì±… ë¬¸ì œ**

| ì¼€ì´ìŠ¤ | ì›ì¸ | ì±…ì„ step | í•´ê²° ê°€ëŠ¥ì„± |
|--------|------|-----------|-------------|
| Hanwha "4ëŒ€ìœ ì‚¬ì•”" (proposal) vs "ìœ ì‚¬ì•”(8ëŒ€)" (scope) | Excel alias ë¯¸ë“±ë¡ | Step2 | âŒ êµ¬ì¡°ì  ë¶ˆê°€ (Excel ìˆ˜ë™ ì¶”ê°€ í•„ìš”) |
| Heungkuk "ë‹´ë³´ëª… A" (proposal) vs "ë‹´ë³´ëª… B" (scope) | Excel alias ë¯¸ë“±ë¡ | Step2 | âŒ êµ¬ì¡°ì  ë¶ˆê°€ (Excel ìˆ˜ë™ ì¶”ê°€ í•„ìš”) |
| Hyundai "ì•”ì§„ë‹¨ë¹„ë³´ì¥" â†’ "ì•”ì§„ë‹¨ë¹„" | Step4 variant ìƒì„± ì§€ì› | Step4 | âœ… ê°€ëŠ¥ (evidenceë§Œ, code ë¶€ì—¬ëŠ” ì•ˆ ë¨) |

**êµ¬ì¡°ì  í•œê³„**:
- Step2ëŠ” **proposal ëª…ì¹­ì„ ì§ì ‘ ë³´ì§€ ì•ŠìŒ** (Step0/1ì´ ì¶”ì¶œí•œ `coverage_name_raw`ë§Œ ì‚¬ìš©)
- Proposal PDFì—ì„œ ì¶”ì¶œí•œ ë‹´ë³´ëª…ì´ Excel aliasì™€ ë‹¤ë¥´ë©´ â†’ **Step2ì—ì„œ unmatched í™•ì •**
- Step7 amount extractionì€ proposal ë‹´ë³´ëª… ì‚¬ìš©í•˜ì§€ë§Œ **canonical code ë¶€ì—¬ ê¶Œí•œ ì—†ìŒ**

---

### Q5: í˜„ì¬ êµ¬ì¡°ì—ì„œ Hanwha/Heungkuk ì¼€ì´ìŠ¤ëŠ” ì›ì²œì ìœ¼ë¡œ í•´ê²° ê°€ëŠ¥í•œê°€?

**Answer**: **âŒ êµ¬ì¡°ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥ (í˜„ì¬ pipeline êµ¬ì¡° ë‚´ì—ì„œ)**

**ì´ìœ **:
1. **Step0-1 ì¶”ì¶œ**: ê°€ì…ì„¤ê³„ì„œì—ì„œ "4ëŒ€ìœ ì‚¬ì•”" ì¶”ì¶œ ì„±ê³µ
2. **Step2 mapping**: Excelì— "4ëŒ€ìœ ì‚¬ì•”" alias ì—†ìŒ â†’ `unmatched`
3. **Step4 evidence**: Hanwha variant ìƒì„±ìœ¼ë¡œ "ìœ ì‚¬ì•”(4ëŒ€)" ê²€ìƒ‰ â†’ ì¦ê±° ë°œê²¬ (evidence_status=found)
4. **Step5 cards**: `mapping_status=unmatched`, `evidence_status=found` ì¹´ë“œ ìƒì„± (SSOT í™•ì •)
5. **Step7 amount**: ê°€ì…ì„¤ê³„ì„œ "4ëŒ€ìœ ì‚¬ì•”" ê¸ˆì•¡ ì¶”ì¶œ ì„±ê³µ, í•˜ì§€ë§Œ **scopeì— "4ëŒ€ìœ ì‚¬ì•”" ì—†ìŒ** â†’ `coverage_code=None` â†’ ë§¤ì¹­ ì‹¤íŒ¨

**Mismatch ë°œìƒ ì§€ì **:
- Proposal ë‹´ë³´ëª… ("4ëŒ€ìœ ì‚¬ì•”") â‰  Scope ë‹´ë³´ëª… ("ìœ ì‚¬ì•”(8ëŒ€)") â‰  Canonical ë‹´ë³´ëª… ("ìœ ì‚¬ì•”ì§„ë‹¨ë¹„(4ëŒ€ìœ ì‚¬ì•”ì œì™¸)")
- **3ê°œ ëª…ì¹­ ë¶ˆì¼ì¹˜, but alias layer ì—†ìŒ**

**í˜„ì¬ êµ¬ì¡°ì˜ í•´ê²°ì±…**:
1. âœ… Excel íŒŒì¼ì— "4ëŒ€ìœ ì‚¬ì•”" â†’ A3300_4 alias ìˆ˜ë™ ì¶”ê°€ (Step2 mapping ì„±ê³µ)
2. âŒ ì½”ë“œë¡œ ìë™ ì¶”ë¡  (fuzzy matching ê¸ˆì§€ by SSOT contract)

---

## 3ï¸âƒ£ Step Alignment Evaluation

| Step | ì—­í•  ëª…í™•ì„± | í‰ê°€ | ë¹„ê³  |
|------|-------------|------|------|
| **Step0: Scope Filter** | âœ… ëª…í™• | ë‹´ë³´ í›„ë³´ 1ì°¨ í•„í„°ë§ (table row, ë¹„ë¬¸ì¥) | ì—­í•  ì ì ˆ |
| **Step1-sanitize: Sanitize Scope** | âš ï¸ ëª¨í˜¸ | Mapping í›„ unmatched ì¶”ê°€ ì •ì œ â†’ **ìˆœì„œ ì—­ì „** (sanitizeê°€ mapping ì „ì— ì™€ì•¼ í•¨) | **êµ¬ì¡° ì¬ì •ì˜ í•„ìš”** |
| **Step2: Canonical Mapping** | âœ… ëª…í™• | Coverage ì •ì²´ì„± í™•ì • (coverage_code ë¶€ì—¬) | ì—­í•  ì ì ˆ, but **alias í™•ì¥ í•„ìš”** |
| **Step3: Extract Text** | âœ… ëª…í™• | Infrastructure (í…ìŠ¤íŠ¸ ì¶”ì¶œ) | ì—­í•  ì ì ˆ |
| **Step4: Evidence Search** | âŒ ì±…ì„ ê³¼ë‹¤ | Evidence ê²€ìƒ‰ + **íšŒì‚¬ë³„ variant heuristic** | **Variant ìƒì„±ì€ Step2 ì´ì „ì— ì™€ì•¼ í•¨** |
| **Step5: Build Cards** | âœ… ëª…í™• | SSOT ìƒì„± (ë‹´ë³´ ëª©ë¡ í™•ì •) | ì—­í•  ì ì ˆ |
| **Step7: Amount Extraction** | âš ï¸ ì¤‘ë³µ ë§¤ì¹­ | Proposal ë‹´ë³´ëª… â†’ scope ë§¤ì¹­ â†’ **Step2ì™€ ë…ë¦½ì  ë§¤ì¹­** | **ì¤‘ë³µ ë¡œì§, í†µí•© í•„ìš”** |

---

### ì„¸ë¶€ í‰ê°€

#### âŒ **Step4: Evidence Search â€” ì—­í•  ê³¼ë‹¤**

**ë¬¸ì œ**:
- Evidence ê²€ìƒ‰ (ë³¸ì—…)
- + Query variant ìƒì„± (Hyundai/Hanwha íŠ¹í™”)
- + Fallback pattern (token-AND search)

**ì´ stepì— ìˆìœ¼ë©´ ì•ˆ ë˜ëŠ” ë¡œì§**:
```python
# step4_evidence_search/search_evidence.py:57-213
def _generate_hyundai_query_variants(coverage_name):
    # ì§„ë‹¨ë¹„ â†” ì§„ë‹¨ ë³€í™˜
    # suffix ì œê±° (ë‹´ë³´, íŠ¹ì•½, ë³´ì¥)

def _generate_hanwha_query_variants(coverage_name):
    # 4ëŒ€ìœ ì‚¬ì•” â†” ìœ ì‚¬ì•”(4ëŒ€) â†” ìœ ì‚¬ì•” ë¸Œë¦¿ì§€
    # 6ê°œ suffix variants
```

**ì™œ ë¬¸ì œì¸ê°€**:
- **Variant ìƒì„± = alias ì •ì˜ ë¡œì§** â†’ Step2 ì´ì „ì— ì™€ì•¼ í•¨
- Step4ëŠ” **ì´ë¯¸ mapping ì‹¤íŒ¨í•œ ë‹´ë³´ì— ëŒ€í•´ ë³´ìƒ ì‹œë„** (fallback) â†’ êµ¬ì¡°ì ìœ¼ë¡œ ëŠ¦ìŒ

**ì˜¬ë°”ë¥¸ ìœ„ì¹˜**:
- Step2 ì´ì „ì— **Alias Expansion Layer** ì¶”ê°€
- Proposal ëª…ì¹­ â†’ variant ìƒì„± â†’ mapping ì‹œë„ (4-tier + variant tier)

---

#### âš ï¸ **Step1-sanitize â€” ìˆœì„œ ì—­ì „**

**ë¬¸ì œ**:
- í˜„ì¬: Step2 mapping **í›„** sanitize (mapping ê²°ê³¼ë¥¼ ë³´ê³  unmatched ì •ì œ)
- ì˜¬ë°”ë¥¸ ìˆœì„œ: sanitize **ë¨¼ì €** (condition sentence ì œê±°), mapping **ë‚˜ì¤‘**

**ì¦ê±°**:
```python
# step1_sanitize_scope/run.py:76-84
if mapping_status == 'unmatched' or not coverage_code:
    if sentence_like_pattern:
        return True, 'SENTENCE_LIKE_UNMATCHED'
```

â†’ `mapping_status`ë¥¼ ë³´ê³  íŒë‹¨ = **mapping í›„ ì‹¤í–‰ë˜ì–´ì•¼ í•œë‹¤ëŠ” ì˜ë¯¸**

**ë¬¸ì œì **:
- Sanitizeê°€ mapping ê²°ê³¼ì— ì˜ì¡´ â†’ **circular dependency risk**
- Step2 ì‹¤íŒ¨ ì‹œ sanitize ê¸°íšŒ ìƒì‹¤ (ì´ë¯¸ unmatchedë¡œ í™•ì •)

---

#### âš ï¸ **Step7: Amount Extraction â€” ì¤‘ë³µ ë§¤ì¹­**

**ë¬¸ì œ**:
- Step2: `coverage_name_raw` (scope) â†’ canonical code
- Step7: proposal ë‹´ë³´ëª… â†’ scope `coverage_name_raw` â†’ canonical code (ê°„ì ‘)

**ì¦ê±°**:
```python
# step7_amount_extraction/extract_and_enrich_amounts.py:322-366
def match_proposal_to_coverage_code(pairs, scope_mapped_csv):
    # Load scope_mapped.csv: coverage_name_raw -> coverage_code
    coverage_map[norm_name] = (code, raw_name)

    # Match proposal pairs to coverage_code
    for pair in pairs:
        norm = normalize_coverage_name_for_matching(pair.coverage_name_raw)
        if norm in coverage_map:
            code = coverage_map[norm]
```

**ë¬¸ì œì **:
- **Normalization ê·œì¹™ ì¤‘ë³µ**: Step2 `_normalize()` vs Step7 `normalize_coverage_name_for_matching()`
- Step7 ì„±ê³µí•´ë„ **coverage_code ì¬ë¶€ì—¬ ì•ˆ í•¨** (amount í•„ë“œë§Œ ì¶”ê°€)
- Step2 ì‹¤íŒ¨ + Step7 ì„±ê³µ ì‹œ **UNCONFIRMEDë¡œ ë‚¨ìŒ** (êµ¬ì¡°ì  ì†ì‹¤)

---

## 4ï¸âƒ£ êµ¬ì¡°ì  ê²°ë¡  ë° ì¬ì •ì˜ í•„ìš” ì‚¬í•­

### ì§€ê¸ˆ êµ¬ì¡°ë¡œ ì¶©ë¶„í•œ ê²ƒ

1. âœ… **ê°€ì…ì„¤ê³„ì„œ table ì¶”ì¶œ**: Step0 scope filter ì •ì°© (table-based filtering)
2. âœ… **Canonical mapping ê³„ì•½**: Excel ê¸°ë°˜ 4-tier matching (exact/normalized/alias/normalized_alias)
3. âœ… **SSOT ìƒì„±**: Step5 coverage cards (matched + unmatched ëª¨ë‘ í¬í•¨)
4. âœ… **Evidence ê²€ìƒ‰**: 3ê°œ doc type ë…ë¦½ ê²€ìƒ‰ + hits_by_doc_type ê¸°ë¡
5. âœ… **Amount ì¶”ì¶œ**: Type A/B proposal table parsing + multi-line merging

---

### ì§€ê¸ˆ êµ¬ì¡°ë¡œ ë¶ˆê°€ëŠ¥í•œ ê²ƒ (êµ¬ì¡°ì  í•œê³„)

1. âŒ **Proposal ëª…ì¹­ â‰  Scope ëª…ì¹­ ìë™ í•´ì„**
   - ì˜ˆ: "4ëŒ€ìœ ì‚¬ì•”" (proposal) â†’ "ìœ ì‚¬ì•”(8ëŒ€)" (scope) ë§¤ì¹­
   - í˜„ì¬: Excel alias ìˆ˜ë™ ë“±ë¡ í•„ìˆ˜
   - í•œê³„: Excel ì—†ìœ¼ë©´ ì˜êµ¬ `unmatched`

2. âŒ **Semantic equivalence ì¶”ë¡ **
   - ì˜ˆ: "ì•”ì§„ë‹¨ë¹„" â†” "ì•” ì§„ë‹¨" â†” "ì•”ì§„ë‹¨ê¸ˆ" ë™ì¹˜ íŒì •
   - í˜„ì¬: normalized matchingë§Œ (ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±°)
   - í•œê³„: í˜•íƒœì†Œ ë³€í˜• / ìœ ì˜ì–´ ë¯¸ì§€ì›

3. âŒ **Variant ìƒì„± íƒ€ì´ë° ë¬¸ì œ**
   - í˜„ì¬: Step4ì—ì„œ variant ìƒì„± (mapping í›„)
   - ë¬¸ì œ: Step2 ì‹¤íŒ¨ â†’ Step4 variant ë¬´ìš©ì§€ë¬¼
   - í•œê³„: Variantë¡œ evidence ì°¾ì•„ë„ `coverage_code=None` ìœ ì§€

4. âŒ **Step2-Step7 mapping ë¡œì§ ë¶„ì‚°**
   - í˜„ì¬: Step2 (scope â†’ canonical), Step7 (proposal â†’ scope â†’ canonical)
   - ë¬¸ì œ: ì •ê·œí™” ê·œì¹™ ì¤‘ë³µ, Step7 ì„±ê³µí•´ë„ code ì¬ë¶€ì—¬ ì•ˆ í•¨
   - í•œê³„: Step2 ì‹¤íŒ¨ ì‹œ Step7 ì„±ê³µì´ SSOTì— ë°˜ì˜ ì•ˆ ë¨

---

### ì¬ì •ì˜ê°€ í•„ìš”í•œ Step

#### 1. **Step1-sanitize â†’ Step1.5ë¡œ ì´ë™ (mapping ì „ìœ¼ë¡œ)**

**í˜„ì¬**:
```
Step0 (filter) â†’ Step1-extract (legacy) â†’ Step2 (mapping) â†’ Step1-sanitize (cleanup) â†’ Step5 (cards)
```

**ì œì•ˆ**:
```
Step0 (filter) â†’ Step1-sanitize (cleanup FIRST) â†’ Step2 (mapping) â†’ Step5 (cards)
```

**ì´ìœ **:
- SanitizeëŠ” **mapping ë…ë¦½ì ** (condition sentence ì œê±°)
- Mapping ì „ì— ì •ì œí•´ì•¼ Step2 ì„±ê³µë¥  í–¥ìƒ

---

#### 2. **Step2 ì´ì „ì— Alias Expansion Layer ì¶”ê°€**

**í˜„ì¬**:
```
Step0 (extract) â†’ Step2 (mapping with Excel only)
                â†“
            unmatched â†’ Step4 (variant ìƒì„±, í•˜ì§€ë§Œ code ì¬ë¶€ì—¬ ì•ˆ í•¨)
```

**ì œì•ˆ**:
```
Step0 (extract) â†’ Step1.5 (Alias Expansion: Hyundai/Hanwha variants)
                â†’ Step2 (mapping with Excel + expanded aliases)
                â†’ Step4 (evidence search only, NO variant logic)
```

**Alias Expansion Layer ì—­í• **:
- Input: `coverage_name_raw` (proposal ëª…ì¹­)
- Output: `[original, variant1, variant2, ...]` (ìµœëŒ€ 6ê°œ)
- Logic: Hyundai/Hanwha rules (í˜„ì¬ Step4 variant ìƒì„± ë¡œì§ ì´ë™)
- Step2ëŠ” **ëª¨ë“  variantì— ëŒ€í•´ mapping ì‹œë„** (first match wins)

**íš¨ê³¼**:
- Hanwha "4ëŒ€ìœ ì‚¬ì•”" â†’ variant "ìœ ì‚¬ì•”(4ëŒ€)" ìƒì„± â†’ Step2 mapping ì„±ê³µ (Excelì— ë“±ë¡ë˜ì–´ ìˆë‹¤ë©´)
- Step4ëŠ” pure evidence searchë§Œ ë‹´ë‹¹ (ì—­í•  ëª…í™•í™”)

---

#### 3. **Step7 Amount Matchingì„ Step2.5ë¡œ í†µí•©**

**í˜„ì¬**:
```
Step2 (scope â†’ canonical) ... (ì—¬ëŸ¬ step) ... Step7 (proposal â†’ scope â†’ canonical)
```

**ì œì•ˆ**:
```
Step2 (scope â†’ canonical)
  â†“
Step2.5 (Proposal Amount Pre-matching: proposal ë‹´ë³´ëª… â†’ scope ë§¤ì¹­ ì‹œë„)
  â†“
  if matched:
    update coverage_code (Step2 ì‹¤íŒ¨ ê±´ ë³µêµ¬)
  â†“
Step5 (cards with corrected mapping_status)
  â†“
Step7 (amount enrichment only, NO matching)
```

**Step2.5 ì—­í• **:
- Input: `data/evidence_text/{insurer}/ê°€ì…ì„¤ê³„ì„œ/*.page.jsonl`
- Output: `data/scope/{insurer}_proposal_aliases.csv` (proposal ë‹´ë³´ëª… â†’ scope ë‹´ë³´ëª… ë§¤í•‘)
- Logic:
  1. Proposalì—ì„œ (ë‹´ë³´ëª…, ê¸ˆì•¡) í˜ì–´ ì¶”ì¶œ
  2. Normalize proposal ë‹´ë³´ëª…
  3. Scope `coverage_name_raw`ì™€ ë§¤ì¹­ ì‹œë„
  4. ë§¤ì¹­ ì„±ê³µ ì‹œ `proposal_name â†’ scope_name â†’ coverage_code` ê²½ë¡œ ê¸°ë¡
  5. Step2 ì‹¤íŒ¨ ê±´ ì¤‘ Step2.5 ì„±ê³µ ê±´ â†’ `mapping_status=matched` ì—…ë°ì´íŠ¸

**íš¨ê³¼**:
- Step2-Step7 ì¤‘ë³µ ë¡œì§ ì œê±°
- Proposal ëª…ì¹­ ê¸°ë°˜ ë§¤ì¹­ ê²°ê³¼ê°€ **SSOT ìƒì„± ì „ì— ë°˜ì˜**
- Step7ì€ pure amount enrichment (matching ì±…ì„ ì œê±°)

---

## 5ï¸âƒ£ ë‹¤ìŒ ë‹¨ê³„ í›„ë³´ (NEXT STEP Candidates)

### **Option A: STEP NEXT-22 â€” Alias Expansion Layer ì‹ ì„¤** (ì¶”ì²œ â­)

**ëª©í‘œ**: Proposal ëª…ì¹­ variant ìƒì„±ì„ Step2 ì´ì „ìœ¼ë¡œ ì´ë™, mapping ì„±ê³µë¥  í–¥ìƒ

**ë³€ê²½**:
1. `pipeline/step1.5_alias_expansion/` ìƒì„±
   - Input: `{insurer}_scope.csv` (raw proposal ëª…ì¹­)
   - Output: `{insurer}_scope_expanded.csv` (original + variants)
   - Logic: Hyundai/Hanwha variant rules (Step4ì—ì„œ ì´ë™)
2. Step2 mapping ì…ë ¥ì„ `scope_expanded.csv`ë¡œ ë³€ê²½
3. Step4 variant ìƒì„± ë¡œì§ ì œê±° (pure evidence searchë§Œ ìœ ì§€)

**íš¨ê³¼**:
- Hanwha "4ëŒ€ìœ ì‚¬ì•”" â†’ "ìœ ì‚¬ì•”(4ëŒ€)" variant ìƒì„± â†’ Step2 mapping ì„±ê³µ ê°€ëŠ¥
- **ë‹¨, Excel alias ë“±ë¡ í•„ìˆ˜** (variant ìƒì„±ë§Œìœ¼ë¡œëŠ” ë¶ˆì¶©ë¶„, Excelì— "ìœ ì‚¬ì•”(4ëŒ€)" alias ìˆì–´ì•¼ í•¨)

**í•œê³„**:
- Excel alias ì˜ì¡´ ì—¬ì „ (ìë™ ì¶”ë¡  ì•„ë‹˜)
- Variant í­ë°œ ìœ„í—˜ (Hanwha 6ê°œ Ã— 30 coverages = 180 variants)

---

### **Option B: STEP NEXT-23 â€” Proposal-Scope Alias Registry êµ¬ì¶•**

**ëª©í‘œ**: Proposal ë‹´ë³´ëª… â†” Scope ë‹´ë³´ëª… ë§¤í•‘ í…Œì´ë¸” ìƒì„± (Excelê³¼ ë…ë¦½)

**ë³€ê²½**:
1. `data/sources/mapping/proposal_scope_aliases.json` ìƒì„±
   ```json
   {
     "hanwha": {
       "4ëŒ€ìœ ì‚¬ì•”": "ìœ ì‚¬ì•”(8ëŒ€)",
       "í†µí•©ì•”(4ëŒ€ìœ ì‚¬ì•”ì œì™¸)": "ìœ ì‚¬ì•”ì§„ë‹¨ë¹„(4ëŒ€ìœ ì‚¬ì•”ì œì™¸)"
     },
     "heungkuk": {
       "ë‹´ë³´A": "ë‹´ë³´B"
     }
   }
   ```
2. Step2 ì´ì „ì— alias registry ê¸°ë°˜ proposal â†’ scope ëª…ì¹­ ë³€í™˜
3. ë³€í™˜ëœ scope ëª…ì¹­ìœ¼ë¡œ Step2 mapping ì‹œë„

**íš¨ê³¼**:
- Proposal-Scope mismatch í•´ê²° (ë³´í—˜ì‚¬ë³„ alias ìˆ˜ë™ ê´€ë¦¬)
- Excel íŒŒì¼ ë³€ê²½ ì—†ì´ alias ì¶”ê°€ ê°€ëŠ¥

**í•œê³„**:
- ì—¬ì „íˆ ìˆ˜ë™ ë“±ë¡ í•„ìš” (ìë™ ì¶”ë¡  ì•„ë‹˜)
- 2ê°œ mapping íŒŒì¼ ê´€ë¦¬ (Excel + JSON)

---

### **Option C: STEP NEXT-24 â€” Sanitize-Mapping ìˆœì„œ ì¬ì •ì˜** (Quick Win)

**ëª©í‘œ**: Step1-sanitizeë¥¼ Step2 ì´ì „ìœ¼ë¡œ ì´ë™ (ìˆœì„œ ì •ìƒí™”)

**ë³€ê²½**:
1. `step1_sanitize_scope/run.py` inputì„ `{insurer}_scope.csv`ë¡œ ë³€ê²½ (í˜„ì¬ëŠ” `_mapped.csv`)
2. Sanitize ë¡œì§ì—ì„œ `mapping_status` ì˜ì¡´ ì œê±°
3. Pipeline ìˆœì„œ: Step0 â†’ Step1-sanitize â†’ Step2 â†’ Step5

**íš¨ê³¼**:
- Condition sentence ì œê±°ê°€ mapping ì „ì— ìˆ˜í–‰ â†’ Step2 ì„±ê³µë¥  í–¥ìƒ
- Circular dependency ì œê±°

**í•œê³„**:
- Hanwha/Heungkuk alias ë¬¸ì œ ë¯¸í•´ê²° (ìˆœì„œ ë³€ê²½ë§Œìœ¼ë¡œëŠ” ë¶ˆì¶©ë¶„)

---

## ğŸ“‹ Final Recommendations

### ìš°ì„ ìˆœìœ„ 1: **STEP NEXT-24 (Sanitize ìˆœì„œ ì •ìƒí™”)** â† Quick Win
- êµ¬ì¡°ì  ìˆœì„œ ì—­ì „ í•´ê²°
- ë³€ê²½ ë²”ìœ„ ì‘ìŒ (Step1 input ë³€ê²½ë§Œ)
- ì¦‰ì‹œ íš¨ê³¼ (mapping ì„±ê³µë¥  ì†Œí­ í–¥ìƒ)

### ìš°ì„ ìˆœìœ„ 2: **STEP NEXT-22 (Alias Expansion Layer)** â† Structural Fix
- Variant ìƒì„±ì„ Step2 ì´ì „ìœ¼ë¡œ ì´ë™
- Step4 ì—­í•  ëª…í™•í™” (evidence search only)
- Hanwha/Heungkuk ì¼ë¶€ ì¼€ì´ìŠ¤ í•´ê²° ê°€ëŠ¥ (Excel alias ë“±ë¡ ë³‘í–‰ í•„ìš”)

### ìš°ì„ ìˆœìœ„ 3: **STEP NEXT-23 (Proposal-Scope Alias Registry)** â† Long-term
- Proposal-Scope mismatch ê·¼ë³¸ í•´ê²°
- Excel ë…ë¦½ì  alias ê´€ë¦¬
- ì¥ê¸° ìš´ì˜ ê´€ì ì—ì„œ í•„ìš” (ë‹¨, ìˆ˜ë™ ê´€ë¦¬ ë¶€ë‹´ ì¦ê°€)

---

## ğŸš« ê¸ˆì§€ ì‚¬í•­ Checklist

- âœ… ê¸ˆì•¡ ì¶”ì¶œ ë¡œì§ ìˆ˜ì • ì•ˆ í•¨
- âœ… Fuzzy matching ì œì•ˆ ì•ˆ í•¨
- âœ… ë‹¨ê¸° KPI ê°œì„  íŒ¨ì¹˜ ì•ˆ í•¨
- âœ… inca-rag-demo ì°¸ì¡° ì•ˆ í•¨
- âœ… ì½”ë“œ ë³€ê²½ ì•ˆ í•¨ (ë¶„ì„ only)

---

**Document Version**: 1.0
**Completion Date**: 2025-12-30
**Next Action**: STEP NEXT-24 (Sanitize ìˆœì„œ ì •ìƒí™”) ì°©ìˆ˜ ê²€í† 
